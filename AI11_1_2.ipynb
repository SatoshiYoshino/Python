{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df =pd.read_csv('sample11_2_1.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データを学習用と評価用に分離\n",
    "train = df[:1000]\n",
    "test = df[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#入力データの定義\n",
    "x=tf.placeholder(tf.float32,[None,2])\n",
    "#プレースフォルダを用いて入力を定義する。x1,x2の2変数なので入力は２となる\n",
    "#またデータの個数は任意の数が指定できるようにNoneを指定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重みをバイアスの定義\n",
    "W = tf.Variable(tf.zeros([2,2],tf.float32))\n",
    "b=tf.Variable(tf.zeros([1,2],tf.float32))\n",
    "# Variableは、その名の通り変数。重み、バイアスは学習が進むに連れて徐々に値を変えるので変数として定義する\n",
    "# 　初期値は、0としてもみは２×２行列、バイアスは１×２行列とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 入力データは１度値が設定されれば値が変更される事はない\n",
    "#Tensorfolowではこのように計算グラフを定義した時は値が決まっていないが計算を実行する際には値が設定されて\n",
    "# その後変更されないと言うものは「プレースフォルダー」、計算実行中に随時値が変更されるものを変数と言う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#出力の定義\n",
    "#(1)入力に重みを掛け、バイアスを足す\n",
    "#(2)ソフトマックス関数を通し確率に変換\n",
    "#yはtype１の確率、type2の確率の配列\n",
    "# matmuは行列の配列とみなして行列積を計算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "# tf.nn　ニューラルネットワークのsoftmax関数\n",
    "# matmul行列の配列だとみなして行列の積を計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "入力に対して重みを掛け、バイアスを足し算している。\n",
    "次にそれを活性化関数であるソフトマクス関数に渡しています。\n",
    "ソフトマックス関数は、TensorFlowのライブラリで定義されている為、呼び出すだけで計算グラフが作成されます。\n",
    "出力yは与えられた入力がtype1（赤丸）でありそうか、type2（青丸）でありそうかを確率として表現する　例えば[0.83,0.17]のようになる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習処理の定義\n",
    "ここまででニューラルネットワークはできた。次に重みとバイアスを調整する為の学習処理を定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 正解データ\n",
    "t = tf.placeholder(tf.float32,[None,2])\n",
    "# プレースフォルダーを使用に正解データ、100%赤丸（0%青星）、１００％青星（0%赤丸）と言うデータを読み込めるようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 交差エントロピー誤差を定義\n",
    "# 各データに対して交差エントロピー値を計算し\n",
    "# 次に全交差エントロピーを合計\n",
    "# reduce_sumでは多次元の配列を一気に足すという事もできるが今回はわかりやすさの為２段階に分けた\n",
    "cross_entropy = tf.reduce_sum(tf.reduce_sum(t*tf.log(y),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化処理を定義\n",
    "train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "\n",
    "# 定義した交差エントロピー誤差を最小化する最適化計算を定義する\n",
    "#　最適化処理では、非常に複雑な事が行われているがTensorflowではライブラリとして用意されているので呼び出すだけで良い。\n",
    "# 今回は、Adamと呼ばれる勾配法と呼ばれる改良手法を利用する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正答率計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(t,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) \n",
    "\n",
    "# tf.equal(x, y) →x==yの真理値を返す　bool型（True, False）\n",
    "# tf.argmax(y,1)は、計算データで、tf.argmax(t,1)は、教師データ\n",
    "# tf.reduce_meanは、平均値計算　\n",
    "# tf.castは、trueは１.０　False0.0に変換する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "argmaxについて\n",
    "渡された配列のうち、最大要素のインデックスを返す。例えば[0.8,0.2]であれば0、[0.3,0.7]であれば1を返すとした場合、\n",
    "これを出力y（計算されたもの）、教師データt（予めわかっているもの）について計算する。なお、y,tは実際には２次元配列なので軸１（列）単位で比較します。\n",
    "結果は１次元配列になる\n",
    "\n",
    "ergalについて\n",
    "第１引数、第２引数が等しいかどうかをTrue、Falseで返す。結果の次元数は変わらずに今回は[True,False,True]という値になる\n",
    "\n",
    "castについて\n",
    "第１引数と第２引数のデータ型に変換する。Trueであれば1.0、Falseであれば0.0になる\n",
    "ここまでくればreduce_meanを利用し平均値を計算できる。例えば[1.0,0.0,1.0]であれば0.666...という値が計算される\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習の実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまででニューラルネットワーク、学習処理、また、正答率の計算が定義できた。\n",
    "ここからは実際にデータを与え、評価を行っていく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# セッションを作成し変数を初期化する\n",
    "#グラフの事項単位をセッション（Session）と言う\n",
    "# 変数(Variable)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# まずセッションを作成する\n",
    "# またセッションで利用する変数は初期化が必要\n",
    "# これには　global_variables_initializer　という処理を実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ニューラルネットワークを学習させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "# 訓練データの一部を取り出して実行する\n",
    "    start = (i * 100)% 1000\n",
    "    batch = train[start:].head(100)\n",
    "    xs = batch[['x1','x2']]\n",
    "    ts = batch[['t1','t2']]\n",
    "    sess.run(train_step,{x: xs,t:ts})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークの学習は一度だけでなく繰り返し学習を行う。\n",
    "その際に全部の訓練データを与えるのでなく一部を与える。このようにする主な理由は計算時間を短縮する為です。これをミニバッチという。\n",
    "データの取り出しかたについてはpandasに関する事項ですが、少し補足するとstartは0,100,200のように100刻みの数値になる。\n",
    "1000,1100になると「％1000」として余りの0,100と計算される。次にスライスを使用し「１００移行」「２００以降」のように訓練データの一部を取り出す。\n",
    "最後必要なのは取り出したデータのうち１００個だけなので、headメソッドを使用し先頭１００個を取り出す。このようにして１００個のデータを取り出したあと、\n",
    "入力と正解データに分離を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ニューラルネットワークの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46\n"
     ]
    }
   ],
   "source": [
    "# 評価データを　用いて正答率を計算\n",
    "print(sess.run(accuracy,{x:test[['x1','x2']],t:test[['t1','t2']]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習したニューラルネットワークに対して未知のデータを与えた場合、正解率46％という成績になった"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
