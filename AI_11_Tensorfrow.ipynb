{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューロンの動作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力に対して出力を決定するルールを活性化関数と言う。\n",
    "\n",
    "・活性化関数<br>\n",
    "・ステップ関数<br>\n",
    "・シグモイド関数<br>\n",
    "・ReLU関数<br>\n",
    "・ソフトマックス関数<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ステップ関数について"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    % \"boldsymbol\"で太字にしている\n",
    "    \\boldsymbol{f(x)} =\n",
    "        % ベクトルや行列は\"left[\"と\"right]\"でベクトルや行列の括弧を作る\n",
    "        % 括弧内に\"array\"環境を展開する\n",
    "        % {c|cc}の形で中央揃え、縦線、中央揃え*2の並びに出来る\n",
    "        \\left[\\begin{array}{c}\n",
    "           0(x>0)1 \\\\\n",
    "         1(x\\geqq0) \\\\\n",
    "        \\end{array}\\right] \\quad\n",
    "$$\n",
    "\n",
    "0を境に急に値が変わると言う特徴がありステップ関数がニューラルネットワークで用いられることはあまりない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### シグモイド関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x)=\\frac{1}{1+e^-x}\n",
    "$$\n",
    "ステップ関数に比べて滑らかに変化すると言う徳昌がありニューラルネットワークによく利用される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    % \"boldsymbol\"で太字にしている\n",
    "    \\boldsymbol{f(x)} =\n",
    "        % ベクトルや行列は\"left[\"と\"right]\"でベクトルや行列の括弧を作る\n",
    "        % 括弧内に\"array\"環境を展開する\n",
    "        % {c|cc}の形で中央揃え、縦線、中央揃え*2の並びに出来る\n",
    "        \\left[\\begin{array}{c}\n",
    "           0(x<0) \\\\\n",
    "         x(x\\geqq0) \\\\\n",
    "        \\end{array}\\right] \\quad\n",
    "$$\n",
    "\n",
    "マイナスの値は全て0,プラスであればそのまま出力される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ソフトマックス関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    " f(x) = \\frac{exp(x^i) }{\\sum_{k=1}^{n}exp(x^k) }  \n",
    "$$\n",
    "\n",
    "入力を確率に変換する。\n",
    "例えば手書きの文字を入力する場合、「0か６かわからない。０の可能性は５０％、１の可能性は０％・・・」のように考え最終的に「最も確からしい」候補を採用する。\n",
    "ソフトマックス関数を使うと入力値からこのような各候補に対する確率を計算することができる。各候補に対する大小関係は変わらないが、「最大１.０」とする事でわかりやすくなる。これを正規化と言う。\n",
    "ソフトマックス関数は、出力層と呼ばれる１番最後の層の活性化関数として利用される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメーターの最適化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教師データ\n",
    "予め答えがわかっている入力と出力の組み合わせを訓練データ、もしくは教師データと呼ぶ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 誤差の認識\n",
    "\n",
    "教師データ（入力と出力セットのデータ）と重みとバイアスの調整がどう関わっているのかの説明<br>\n",
    "ニューラルネットワークでは、１の可能性４０％、２の可能性２５％、３の可能性３５％、以上の事から１が最も可能性が高い。だから書かれているのは１です。のように判定を行う。（それには、ソフトマックス関数が使われる。）\n",
    "それに対して「１と行っているが正しくは２です。」と答えます。つまり「１の可能性０％、２の可能性１００％、３の可能性０％」と答えられる。<br>\n",
    "人間が２を１と間違え、「正しくは２です。と言われると人の脳は、図形パターンを解析し以降別の２が書かれていても「２」と答える事ができる。<br>\n",
    "コンピューター、ニューラルネットワークでは、そこまで高度な事はできず「正しくは２だった。つまり自分が導き出した１は４０％の誤差、２は７５％の誤差、３は３５％の誤差があった」と判断する。<br>\n",
    "この誤差に対して「このような誤差が発生したのは重みのせいだ、重みを変える事で正しく答えられるようにしよう」と言う動作をする\n",
    "\n",
    "ここまでで、誤差がある事まで理解した。<br>\n",
    "この後、重みをどう変えれば誤差を小さくする事ができるか（「２」に対して１００％「２」と答える。つまり誤差０にするのが理想だが、入力データは多数ある為一般的に誤差が０になる事はない。<br>\n",
    "\n",
    "先ほどの「１に対して４０％の誤差、２は７５％、３は３５％」とあったがこれは正しくは「１に対して４０％（４０−０）、２は-75%(25%-100),３は３５％（３５−０）となる。<br>\n",
    "正解のみマイナスになるわけだが、プラスとマイナスが混ざっていると打ち消しあってしまうので通常誤差を２乗してプラスの値にする。これを２乗和誤差と言う。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "E=\\sum_{k=1}^{n}(y_x - t_k)^2\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "y_k：ニューラルネットワークの出力\\\\\n",
    "t_k:教師データ\\\\\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "更にこれをデータ個数分足し合わせて、平均の誤差を計算する\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "E=\\frac{1}{m} \\sum_{j=1}^{m} \\sum_{k=1}^{n}(y_jk - t_jk)^2\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "y^jkは、重みとバイアスを含む式<br>\n",
    "このようなEを損失関数（loss function）と言う　<br>\n",
    "Eの変数は、全重みとバイアスとなる<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最適化\n",
    "\n",
    "損失関数の定義ができたら重み、バイアスの値を変更し、誤差が最小になるような重みとバイアスの値を見つける<br>\n",
    "このような関数に対して最小となる変数の値を見つける方法を最適化問題（Optimization problem）と言う<br>\n",
    "<br>\n",
    "結論、ニューラルネットワークでバックプロバゲーション（誤差逆伝搬法）と言うアルゴリズムが利用される<br>\n",
    "バックプロバゲーションは、最終的に得られた誤差から逆算し、各重みとバイアスをどのようにすれば良いかを決定する<br>\n",
    "<br>\n",
    "逆算とは誤差を表す関数の傾斜を求めどちらに動けば（重みとバイアスをどう変更すれば）関数の値が小さくなるかを決定します<br>\n",
    "このような手法を総括して勾配法と言う\n",
    "<br>\n",
    "勾配法で関数が最小となる値を一度に求める事ができず、ステップを繰り返す事で徐々に最小の値に近づけていく。<br>\n",
    "つまり、ニューラルネットワークでは繰り返し教師データを与え、重み、バイアスの調整を行う必要がある。<br>\n",
    "<br>\n",
    "TensorFlowでは、このバックバケーション、または勾配法の処理はライブラリとして用意されている<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 交差エントロピー\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "誤差がわかれば関数はなんでも大丈夫<br>\n",
    "ニューラルネットワークでは交差エントロビー誤差もよく用いられる<br>\n",
    "＜br＞\n",
    "交差エントロビーについて<br>\n",
    "クッキーの日記がわかりやすかった<br>\n",
    "https://cookie-box.hatenablog.com/entry/2017/05/07/121607＜br＞\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "E=\\sum_{k=1}^{n}t^klog(y^k)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "補足<br>\n",
    "符号化方式が真の確率分布でなくある所定の確率分布qにもとづいている場合にとりうる複数の事象の中から１つの事象を特定する為に必要になるビット数の平均値<br>\n",
    "１回の試行の結果の結果を知らされた時の価値の期待値<br>\n",
    "知らされた時に珍しいほど（確率が低いものが出た場合）価値が高くなる<br>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
